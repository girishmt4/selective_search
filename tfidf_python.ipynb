{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "'''\n",
    "    For the given path, get the List of all files in the directory tree \n",
    "'''\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory \n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "                \n",
    "    return allFiles        \n",
    " \n",
    "\n",
    "dirName = './20News10000';\n",
    "listOfFiles = getListOfFiles(dirName)\n",
    "listOfFiles = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dirName):\n",
    "    listOfFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "#     print(len(listOfFiles))   \n",
    "\n",
    "all_docs=[]\n",
    "for txt_file in listOfFiles:\n",
    "    with open(txt_file,encoding=\"ISO-8859-1\") as f:\n",
    "        all_docs.append(f.read())\n",
    "\n",
    "# print(all_docs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./stoplist.txt\") as stoplist_file:\n",
    "    stopwords=stoplist_file.read().split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133139\n",
      "[ 0.0295251   0.02597884  0.1281937  ...,  0.02546451  0.05213961\n",
      "  0.05212258]\n",
      "[   308    770    989 ..., 127706 127741 130603]\n",
      "[      0     756    1800 ..., 1135419 1135580 1135659]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    " \n",
    "# settings that you use for count vectorizer will go here\n",
    "tfidf_vectorizer=TfidfVectorizer(min_df=1, stop_words=stopwords, use_idf=True)\n",
    " \n",
    "# just send in all your docs here\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(all_docs)\n",
    "sorted_tfidf_mat=tfidf_vectorizer_vectors.sorted_indices()\n",
    "print(sorted_tfidf_mat.shape[1])\n",
    "print(sorted_tfidf_mat.data)\n",
    "print (sorted_tfidf_mat.indices)\n",
    "print (sorted_tfidf_mat.indptr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"tfidf-python.txt\",\"w\")#write mode \n",
    "file1.write(str(sorted_tfidf_mat.shape[1])+\"\\n\") \n",
    "\n",
    "endptr=1\n",
    "\n",
    "for ptr in sorted_tfidf_mat.indptr:\n",
    "    if(ptr < len(sorted_tfidf_mat.indices)):\n",
    "        for x in range(ptr,sorted_tfidf_mat.indptr[endptr]):\n",
    "            file1.write(str(sorted_tfidf_mat.indices[x])+\":\"+str(sorted_tfidf_mat.data[x])+\",\") \n",
    "        endptr += 1\n",
    "        file1.write(\"\\n\")\n",
    "    else:\n",
    "        break\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
